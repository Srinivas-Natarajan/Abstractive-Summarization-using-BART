{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## ***Imports and Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from summarizer import Summarizer,TransformerSummarizer\n",
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\VIT\\SEM-7\\B2 - NLP\\Project\\Code\\curation-corpus-master\\output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tencent gains approval to sell mutual funds to...</td>\n",
       "      <td>Tencent has been granted a licence from the Ch...</td>\n",
       "      <td>http://www.scmp.com/business/companies/article...</td>\n",
       "      <td>Traditional finance houses now being seriously...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India testing blockchains in education, health...</td>\n",
       "      <td>India is testing blockchain applications in ed...</td>\n",
       "      <td>https://www.vccircle.com/niti-aayog-explores-b...</td>\n",
       "      <td>The Indian government's policy think tank, Nit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Higher living wage risks robot takeover of low...</td>\n",
       "      <td>The UK Institute for Fiscal Studies has warned...</td>\n",
       "      <td>https://news.sky.com/story/ifs-living-wage-inc...</td>\n",
       "      <td>Increases in minimum wage levels risk raising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regus WeWork may seek stock-market flotation t...</td>\n",
       "      <td>Co-working start-up WeWork may go public this ...</td>\n",
       "      <td>https://www.fool.com/investing/2018/01/03/will...</td>\n",
       "      <td>Depending on whom you ask, WeWork is either a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD poised to gain market share as Intel pound...</td>\n",
       "      <td>Intel has seen more than $11bn wiped off its m...</td>\n",
       "      <td>https://www.cnbc.com/2018/01/05/amd-is-big-win...</td>\n",
       "      <td>AMD is big winner from chip flaw fiasco as mor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Tencent gains approval to sell mutual funds to...   \n",
       "1  India testing blockchains in education, health...   \n",
       "2  Higher living wage risks robot takeover of low...   \n",
       "3  Regus WeWork may seek stock-market flotation t...   \n",
       "4  AMD poised to gain market share as Intel pound...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Tencent has been granted a licence from the Ch...   \n",
       "1  India is testing blockchain applications in ed...   \n",
       "2  The UK Institute for Fiscal Studies has warned...   \n",
       "3  Co-working start-up WeWork may go public this ...   \n",
       "4  Intel has seen more than $11bn wiped off its m...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.scmp.com/business/companies/article...   \n",
       "1  https://www.vccircle.com/niti-aayog-explores-b...   \n",
       "2  https://news.sky.com/story/ifs-living-wage-inc...   \n",
       "3  https://www.fool.com/investing/2018/01/03/will...   \n",
       "4  https://www.cnbc.com/2018/01/05/amd-is-big-win...   \n",
       "\n",
       "                                     article_content  \n",
       "0  Traditional finance houses now being seriously...  \n",
       "1  The Indian government's policy think tank, Nit...  \n",
       "2  Increases in minimum wage levels risk raising ...  \n",
       "3  Depending on whom you ask, WeWork is either a ...  \n",
       "4  AMD is big winner from chip flaw fiasco as mor...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df_1 = df.drop(\"date\",axis=1)\n",
    "df_1.dropna(inplace=True)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  37639\n",
      "Null records:\n",
      " title              0\n",
      "summary            0\n",
      "url                0\n",
      "article_content    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records: \", len(df_1))\n",
    "print(\"Null records:\\n\", df_1.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_content = df_1[\"article_content\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37,639 articles with no null values\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***BART Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = 'cpu'\n",
    "#torch_device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bart_summarize(text):\n",
    "  \n",
    "  text = text.replace('\\n','')\n",
    "  text_input_ids = tokenizer.batch_encode_plus([text], return_tensors='pt', max_length=1024)['input_ids'].to(torch_device)\n",
    "  summary_ids = model.generate(text_input_ids)           \n",
    "  summary_txt = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "  return summary_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_summary = []\n",
    "for article in art_content[:100]:\n",
    "    bart_summary.append(bart_summarize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save summaries\n",
    " with open('./saves/bart_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(bart_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Load summaries into list\n",
    "with open('saves/bart_summary.pkl', 'rb') as f:\n",
    "    bart_summary = pickle.load(f)\n",
    "print(len(bart_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3425688880978472\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge() \n",
    "bart_results = rouge.get_scores(bart_summary, art_content[:100], avg=True)\n",
    "print(bart_results['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.24376196727960603, 'p': 0.95256595316306, 'f': 0.3425688880978472}, 'rouge-2': {'r': 0.18992568657754003, 'p': 0.8877813022847721, 'f': 0.2626904085860145}, 'rouge-l': {'r': 0.24333340306696757, 'p': 0.9497327716956646, 'f': 0.34184003199002516}}\n"
     ]
    }
   ],
   "source": [
    "print(bart_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save ROUGE Results\n",
    "with open('./saves/bart_results.pkl', 'wb') as f:\n",
    "    pickle.dump(bart_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load BART ROUGE results \n",
    "with open('saves/bart_results.pkl', 'rb') as f:\n",
    "    bart_results = pickle.load(f)\n",
    "print(len(bart_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***T5 Model testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline cannot infer suitable model classes from t5-base",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d96a71d210f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"t5-base\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"t5-base\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_tuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Pipeline cannot infer suitable model classes from {model}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Pipeline cannot infer suitable model classes from t5-base"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = summarizer(text, do_sample=False)[0]['summary_text']\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***BERT Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_summary = []\n",
    "bert_model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n"
     ]
    }
   ],
   "source": [
    "for article in art_content[:100]:\n",
    "    bert_summary.append(''.join(bert_model(article, min_length=60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save BERT Summaries\n",
    "with open('./saves/bert_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(bert_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT summaries into list\n",
    "with open('./saves/bert_summary.pkl', 'rb') as f:\n",
    "    bert_summary = pickle.load(f)\n",
    "print(len(bert_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512665142711876\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "bert_results = rouge.get_scores(bert_summary, art_content[:100], avg=True)\n",
    "print(bert_results['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.35671353293714303, 'p': 0.9987867380091021, 'f': 0.512665142711876}, 'rouge-2': {'r': 0.2884779593282122, 'p': 0.9808698819649082, 'f': 0.4293938466441541}, 'rouge-l': {'r': 0.35671353293714303, 'p': 0.9987867380091021, 'f': 0.512665142711876}}\n"
     ]
    }
   ],
   "source": [
    "print(bert_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/bert_result.pkl', 'wb') as f:\n",
    "    pickle.dump(bert_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load BERT ROUGE results \n",
    "with open('saves/bert_result.pkl', 'rb') as f:\n",
    "    bert_results = pickle.load(f)\n",
    "print(len(bert_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***GPT-2*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 718/718 [00:00<00:00, 144kB/s]\n",
      "Downloading: 100%|██████████| 1.42G/1.42G [02:45<00:00, 9.20MB/s]\n",
      "Downloading: 100%|██████████| 0.99M/0.99M [00:01<00:00, 734kB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:01<00:00, 422kB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:01<00:00, 813kB/s] \n"
     ]
    }
   ],
   "source": [
    "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n"
     ]
    }
   ],
   "source": [
    "gpt2_summary = []\n",
    "for article in art_content[:100]:\n",
    "    gpt2_summary.append(''.join(GPT2_model(article, min_length=60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save GPT2 Summaries\n",
    "with open('./saves/gpt2_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(gpt2_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT2 summaries into list\n",
    "with open('./saves/gpt2_summary.pkl', 'rb') as f:\n",
    "    gpt2_summary = pickle.load(f)\n",
    "print(len(gpt2_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003818950060116\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "gpt2_results = rouge.get_scores(gpt2_summary, art_content[:100], avg=True)\n",
    "print(gpt2_results['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.346430328700958, 'p': 0.9986815098013179, 'f': 0.5003818950060116}, 'rouge-2': {'r': 0.2784888887918763, 'p': 0.9790739542634641, 'f': 0.4160236755825082}, 'rouge-l': {'r': 0.346430328700958, 'p': 0.9986815098013179, 'f': 0.5003818950060116}}\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/gpt2_result.pkl', 'wb') as f:\n",
    "    pickle.dump(gpt2_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load BERT ROUGE results \n",
    "with open('saves/gpt2_result.pkl', 'rb') as f:\n",
    "    gpt2_results = pickle.load(f)\n",
    "print(len(gpt2_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***XLNet Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 779k/779k [00:01<00:00, 401kB/s]\n",
      "Downloading: 100%|██████████| 1.32M/1.32M [00:02<00:00, 486kB/s]\n"
     ]
    }
   ],
   "source": [
    "xlnet_model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n",
      "D:\\Anaconda\\envs\\abstractive\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:882: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  f\"KMeans is known to have a memory leak on Windows \"\n"
     ]
    }
   ],
   "source": [
    "xlnet_summary = []\n",
    "for article in art_content[:100]:\n",
    "    xlnet_summary.append(''.join(xlnet_model(article, min_length=60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save XLNet Summaries\n",
    "with open('./saves/xlnet_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(xlnet_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Load XLNet summaries into list\n",
    "with open('./saves/xlnet_summary.pkl', 'rb') as f:\n",
    "    xlnet_summary = pickle.load(f)\n",
    "print(len(xlnet_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5126260066401299\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "xlnet_results = rouge.get_scores(xlnet_summary, art_content[:100], avg=True)\n",
    "print(xlnet_results['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.36282156276483435, 'p': 0.9984175768160023, 'f': 0.5126260066401299}, 'rouge-2': {'r': 0.2964653852175559, 'p': 0.9773250014001291, 'f': 0.42994633608829863}, 'rouge-l': {'r': 0.36282156276483435, 'p': 0.9984175768160023, 'f': 0.5126260066401299}}\n"
     ]
    }
   ],
   "source": [
    "print(xlnet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/xlnet_result.pkl', 'wb') as f:\n",
    "    pickle.dump(xlnet_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load XLNet ROUGE results \n",
    "with open('saves/xlnet_result.pkl', 'rb') as f:\n",
    "    xlnet_results = pickle.load(f)\n",
    "print(len(xlnet_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***PEGASUS Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "import torch\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.82M/1.82M [00:01<00:00, 1.06MB/s]\n",
      "Downloading: 100%|██████████| 65.0/65.0 [00:00<00:00, 8.34kB/s]\n",
      "Downloading: 100%|██████████| 88.0/88.0 [00:00<00:00, 11.0kB/s]\n",
      "Downloading: 100%|██████████| 3.02k/3.02k [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████| 2.12G/2.12G [06:24<00:00, 5.91MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/pegasus-large\"\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "pegasus_summary = []\n",
    "for article in art_content[:100]:\n",
    "    batch = tokenizer(article, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch)\n",
    "    pegasus_summary.append(tokenizer.batch_decode(translated, skip_special_token=True)[0])\n",
    "print(len(pegasus_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PEGASUS Summaries\n",
    "with open('./saves/pegasus_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(pegasus_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load PEGASUS summaries into list\n",
    "with open('./saves/pegasus_summary.pkl', 'rb') as f:\n",
    "    pegasus_summary = pickle.load(f)\n",
    "print(len(pegasus_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39022612843617793\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "pegasus_results = rouge.get_scores(pegasus_summary, art_content[:100], avg=True)\n",
    "print(pegasus_results['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.2573194659980407, 'p': 0.9968122245958115, 'f': 0.39022612843617793}, 'rouge-2': {'r': 0.20230428093218447, 'p': 0.985872266417941, 'f': 0.3152113315304677}, 'rouge-l': {'r': 0.2573194659980407, 'p': 0.9968122245958115, 'f': 0.39022612843617793}}\n"
     ]
    }
   ],
   "source": [
    "print(pegasus_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/pegasus_results.pkl', 'wb') as f:\n",
    "    pickle.dump(pegasus_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PEGASUS ROUGE results \n",
    "with open('saves/pegasus_results.pkl', 'rb') as f:\n",
    "    pegasus_results = pickle.load(f)\n",
    "print(len(pegasus_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## ***Results*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ***Loading results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load BART ROUGE results \n",
    "with open('saves/bart_results.pkl', 'rb') as f:\n",
    "    bart_results = pickle.load(f)\n",
    "print(len(bart_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load BERT ROUGE results \n",
    "with open('saves/bert_result.pkl', 'rb') as f:\n",
    "    bert_results = pickle.load(f)\n",
    "print(len(bert_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load GPT2 ROUGE results \n",
    "with open('saves/gpt2_result.pkl', 'rb') as f:\n",
    "    gpt2_results = pickle.load(f)\n",
    "print(len(gpt2_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load XLNet ROUGE results \n",
    "with open('saves/xlnet_result.pkl', 'rb') as f:\n",
    "    xlnet_results = pickle.load(f)\n",
    "print(len(xlnet_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load PEGASUS ROUGE results \n",
    "with open('saves/pegasus_results.pkl', 'rb') as f:\n",
    "    pegasus_results = pickle.load(f)\n",
    "print(len(pegasus_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Compiling Scores***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1_scores = [bart_results['rouge-1'],bert_results['rouge-1'],gpt2_results['rouge-1'],xlnet_results['rouge-1'], pegasus_results['rouge-1']]\n",
    "rouge_2_scores = [bart_results['rouge-2'],bert_results['rouge-2'],gpt2_results['rouge-2'],xlnet_results['rouge-2'], pegasus_results['rouge-2']]\n",
    "rouge_l_scores = [bart_results['rouge-l'],bert_results['rouge-l'],gpt2_results['rouge-l'],xlnet_results['rouge-l'], pegasus_results['rouge-l']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"BERT\", \"BART\", \"GPT2\", \"XLNet\",\"PEGASUS\"]\n",
    "rouge_1_recall = [rouge_1_scores[0]['r'], rouge_1_scores[1]['r'], rouge_1_scores[2]['r'], rouge_1_scores[3]['r'], rouge_1_scores[4]['r']]\n",
    "rouge_1_precision = [rouge_1_scores[0]['p'], rouge_1_scores[1]['p'], rouge_1_scores[2]['p'],rouge_1_scores[3]['p'], rouge_1_scores[4]['p']]\n",
    "rouge_1_f = [rouge_1_scores[0]['f'], rouge_1_scores[1]['f'], rouge_1_scores[2]['f'], rouge_1_scores[3]['f'], rouge_1_scores[4]['f']]\n",
    "\n",
    "for i in range(len(rouge_1_recall)):\n",
    "    rouge_1_recall[i] = round(rouge_1_recall[i],4)\n",
    "    rouge_1_precision[i] = round(rouge_1_precision[i],4)\n",
    "    rouge_1_f[i] = round(rouge_1_f[i],4)\n",
    "\n",
    "\n",
    "data_1 = {\n",
    "    'Recall': rouge_1_recall,\n",
    "    'Precision': rouge_1_precision,\n",
    "    'F-Score': rouge_1_f \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_2_recall = [rouge_2_scores[0]['r'], rouge_2_scores[1]['r'], rouge_2_scores[2]['r'], rouge_2_scores[3]['r'], rouge_2_scores[4]['r']]\n",
    "rouge_2_precision = [rouge_2_scores[0]['p'], rouge_2_scores[1]['p'], rouge_2_scores[2]['p'],rouge_2_scores[3]['p'], rouge_2_scores[4]['p']]\n",
    "rouge_2_f = [rouge_2_scores[0]['f'], rouge_2_scores[1]['f'], rouge_2_scores[2]['f'], rouge_2_scores[3]['f'], rouge_2_scores[4]['f']]\n",
    "\n",
    "\n",
    "for i in range(len(rouge_1_recall)):\n",
    "    rouge_2_recall[i] = round(rouge_1_recall[i],4)\n",
    "    rouge_2_precision[i] = round(rouge_1_precision[i],4)\n",
    "    rouge_2_f[i] = round(rouge_1_f[i],4)\n",
    "\n",
    "data_2 = {\n",
    "    'Recall': rouge_2_recall,\n",
    "    'Precision': rouge_2_precision,\n",
    "    'F-Score': rouge_2_f \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_l_recall = [rouge_l_scores[0]['r'], rouge_l_scores[1]['r'], rouge_l_scores[2]['r'], rouge_l_scores[3]['r'], rouge_l_scores[4]['r']]\n",
    "rouge_l_precision = [rouge_l_scores[0]['p'], rouge_l_scores[1]['p'], rouge_l_scores[2]['p'],rouge_l_scores[3]['p'], rouge_l_scores[4]['p']]\n",
    "rouge_l_f = [rouge_l_scores[0]['f'], rouge_l_scores[1]['f'], rouge_l_scores[2]['f'], rouge_l_scores[3]['f'], rouge_l_scores[4]['f']]\n",
    "\n",
    "\"\"\"\n",
    "for i in range(len(rouge_l_recall)):\n",
    "    rouge_l_recall[i] = round(rouge_l_recall[i],4)\n",
    "    rouge_l_precision[i] = round(rouge_l_precision[i],4)\n",
    "    rouge_l_f[i] = round(rouge_l_f[i],4)\n",
    "\"\"\"\n",
    "data_l = {\n",
    "    'Recall': rouge_l_recall,\n",
    "    'Precision': rouge_l_precision,\n",
    "    'F-Score': rouge_l_f \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b6f3750a_49c7_11ec_b565_ac1203413646row1_col1,#T_b6f3750a_49c7_11ec_b565_ac1203413646row1_col2,#T_b6f3750a_49c7_11ec_b565_ac1203413646row3_col0{\n",
       "            background-color:  green;\n",
       "        }</style><table id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Recall</th>        <th class=\"col_heading level0 col1\" >Precision</th>        <th class=\"col_heading level0 col2\" >F-Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646level0_row0\" class=\"row_heading level0 row0\" >BERT</th>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row0_col0\" class=\"data row0 col0\" >0.243800</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row0_col1\" class=\"data row0 col1\" >0.952600</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row0_col2\" class=\"data row0 col2\" >0.342600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646level0_row1\" class=\"row_heading level0 row1\" >BART</th>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row1_col0\" class=\"data row1 col0\" >0.356700</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row1_col1\" class=\"data row1 col1\" >0.998800</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row1_col2\" class=\"data row1 col2\" >0.512700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646level0_row2\" class=\"row_heading level0 row2\" >GPT2</th>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row2_col0\" class=\"data row2 col0\" >0.346400</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row2_col1\" class=\"data row2 col1\" >0.998700</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row2_col2\" class=\"data row2 col2\" >0.500400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646level0_row3\" class=\"row_heading level0 row3\" >XLNet</th>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row3_col0\" class=\"data row3 col0\" >0.362800</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row3_col1\" class=\"data row3 col1\" >0.998400</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row3_col2\" class=\"data row3 col2\" >0.512600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646level0_row4\" class=\"row_heading level0 row4\" >PEGASUS</th>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row4_col0\" class=\"data row4 col0\" >0.257300</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row4_col1\" class=\"data row4 col1\" >0.996800</td>\n",
       "                        <td id=\"T_b6f3750a_49c7_11ec_b565_ac1203413646row4_col2\" class=\"data row4 col2\" >0.390200</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e170b95a58>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_1 = pd.DataFrame(data_1, index=model_names)\n",
    "final_results_1.style.highlight_max(color = 'green', axis = 0)\n",
    "#final_results_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b8d5d248_49c7_11ec_ab70_ac1203413646row1_col1,#T_b8d5d248_49c7_11ec_ab70_ac1203413646row1_col2,#T_b8d5d248_49c7_11ec_ab70_ac1203413646row3_col0{\n",
       "            background-color:  green;\n",
       "        }</style><table id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Recall</th>        <th class=\"col_heading level0 col1\" >Precision</th>        <th class=\"col_heading level0 col2\" >F-Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646level0_row0\" class=\"row_heading level0 row0\" >BERT</th>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row0_col0\" class=\"data row0 col0\" >0.243800</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row0_col1\" class=\"data row0 col1\" >0.952600</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row0_col2\" class=\"data row0 col2\" >0.342600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646level0_row1\" class=\"row_heading level0 row1\" >BART</th>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row1_col0\" class=\"data row1 col0\" >0.356700</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row1_col1\" class=\"data row1 col1\" >0.998800</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row1_col2\" class=\"data row1 col2\" >0.512700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646level0_row2\" class=\"row_heading level0 row2\" >GPT2</th>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row2_col0\" class=\"data row2 col0\" >0.346400</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row2_col1\" class=\"data row2 col1\" >0.998700</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row2_col2\" class=\"data row2 col2\" >0.500400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646level0_row3\" class=\"row_heading level0 row3\" >XLNet</th>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row3_col0\" class=\"data row3 col0\" >0.362800</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row3_col1\" class=\"data row3 col1\" >0.998400</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row3_col2\" class=\"data row3 col2\" >0.512600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646level0_row4\" class=\"row_heading level0 row4\" >PEGASUS</th>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row4_col0\" class=\"data row4 col0\" >0.257300</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row4_col1\" class=\"data row4 col1\" >0.996800</td>\n",
       "                        <td id=\"T_b8d5d248_49c7_11ec_ab70_ac1203413646row4_col2\" class=\"data row4 col2\" >0.390200</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e170b95940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_2 = pd.DataFrame(data_2, index=model_names)\n",
    "final_results_2.style.highlight_max(color = 'green', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_1605acc8_40c1_11ec_87f4_ac1203413646row1_col1,#T_1605acc8_40c1_11ec_87f4_ac1203413646row1_col2,#T_1605acc8_40c1_11ec_87f4_ac1203413646row3_col0{\n",
       "            background-color:  green;\n",
       "        }</style><table id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Recall</th>        <th class=\"col_heading level0 col1\" >Precision</th>        <th class=\"col_heading level0 col2\" >F-Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646level0_row0\" class=\"row_heading level0 row0\" >BERT</th>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row0_col0\" class=\"data row0 col0\" >0.243333</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row0_col1\" class=\"data row0 col1\" >0.949733</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row0_col2\" class=\"data row0 col2\" >0.341840</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646level0_row1\" class=\"row_heading level0 row1\" >BART</th>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row1_col0\" class=\"data row1 col0\" >0.356714</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row1_col1\" class=\"data row1 col1\" >0.998787</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row1_col2\" class=\"data row1 col2\" >0.512665</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646level0_row2\" class=\"row_heading level0 row2\" >GPT2</th>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row2_col0\" class=\"data row2 col0\" >0.346430</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row2_col1\" class=\"data row2 col1\" >0.998682</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row2_col2\" class=\"data row2 col2\" >0.500382</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646level0_row3\" class=\"row_heading level0 row3\" >XLNet</th>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row3_col0\" class=\"data row3 col0\" >0.362822</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row3_col1\" class=\"data row3 col1\" >0.998418</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row3_col2\" class=\"data row3 col2\" >0.512626</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646level0_row4\" class=\"row_heading level0 row4\" >PEGASUS</th>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row4_col0\" class=\"data row4 col0\" >0.257319</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row4_col1\" class=\"data row4 col1\" >0.996812</td>\n",
       "                        <td id=\"T_1605acc8_40c1_11ec_87f4_ac1203413646row4_col2\" class=\"data row4 col2\" >0.390226</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20d02519d30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_l = pd.DataFrame(data_l, index=model_names)\n",
    "final_results_l.style.highlight_max(color = 'green', axis = 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf42f2bfeff635be0c30fde23fb8279f0258ebc834f04fa8a84a754aea3a3133"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('abstractive': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
