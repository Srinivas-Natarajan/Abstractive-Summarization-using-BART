{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHL0orPxD3Bz"
   },
   "source": [
    "# Finetuning Bert for abstractive summarisation \n",
    "In this noteook I want to demonstrate fine-tuning the the model released by Yang Liu and Mirella Lapata for their paper [Text Summarization with Pretrained Encoders](https://arxiv.org/pdf/1908.08345.pdf). I want to start from scratch, as you might if you were approaching this finetuning problem without a tutorial. We will discuss the model and how to pass a new dataset to it. We will then finetune the model on our new dataset and generate some predictions.\n",
    "\n",
    "The authors released their code and weights [here](https://github.com/nlpyang/PreSumm). However, we will base our code on Rémi Louf's [reimplementation](https://github.com/huggingface/transformers/tree/master/examples/summarization). This uses a more up to date version of Huggingface's Transformers library and is more consise. \n",
    "\n",
    "I'm going to assume you are already fairly familiar with the ideas behind BERT. This post will mostly focus on the specifics of using the model. I also recommend you read Yang and Lapata's paper. I will mention their tweaks to the Bert encoder when we come to them. If you just want the final code, have a look in this notebook, or its accompanying Medium post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xqaeh6lhD3B2"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-6f2_leD3B7"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "import glob\n",
    "from modeling_bertabs import BertAbsConfig, BertAbs, build_predictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import logging\n",
    "logging.getLogger().setLevel(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "896BJGgtD3B-"
   },
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "args = Namespace(\n",
    "    adam_b1=0.9,\n",
    "    adam_b2=0.999,\n",
    "    alpha=0.95,\n",
    "    batch_size=8,\n",
    "    beam_size=5,\n",
    "    block_size=512,\n",
    "    block_trigram=True,\n",
    "    data_path=\"../data/private_dataset.file\",\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    max_length=200, \n",
    "    min_length=50,\n",
    "    model_name=\"temp\",\n",
    "    stories_folder='../data/my_own_stories',\n",
    "    subset=400,\n",
    "    train_pct=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9Jbcs-ND3CD"
   },
   "outputs": [],
   "source": [
    "class SummarisationDataset(Dataset):\n",
    "    def __init__(self, path, subset=None):\n",
    "        if path.endswith('.file'):\n",
    "            self.dataset = pd.read_feather(path)\n",
    "        if path.endswith('.csv'):\n",
    "            self.dataset = pd.read_csv(path)\n",
    "        \n",
    "        if subset:\n",
    "            self.dataset = self.dataset.iloc[:subset]\n",
    "        \n",
    "    def __len__(self):\n",
    "         return self.dataset.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        title = \"\"\n",
    "        article = self.dataset.iloc[idx]['text']\n",
    "        article = [s.strip()+'.' for s in article.split('.')]\n",
    "        article = [self.add_missing_period(line) for line in article if len(line) > 0]\n",
    "        article = [s for s in article if s not in ['..', '.']]\n",
    "        \n",
    "        summary = self.dataset.iloc[idx]['summary']\n",
    "        summary = [s.strip()+'.' for s in summary.split('.')]\n",
    "        summary = [self.add_missing_period(line) for line in summary if len(line) > 0]\n",
    "        summary = [s for s in summary if s not in ['..', '.']]\n",
    "        \n",
    "        return title, article, summary\n",
    "    \n",
    "    def add_missing_period(self, line):\n",
    "        END_TOKENS = [\".\", \"!\", \"?\", \"...\", \"'\", \"`\", '\"', u\"\\u2019\", u\"\\u2019\", \")\"]\n",
    "        if line.startswith(\"@highlight\"):\n",
    "            return line\n",
    "        if line[-1] in END_TOKENS and len(line):\n",
    "            return line\n",
    "        return line + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-88sWSmyD3CG"
   },
   "outputs": [],
   "source": [
    "data = SummarisationDataset(args.data_path, subset=args.subset)\n",
    "\n",
    "train_ds, test_ds = train_test_split(data, test_size=1-args.train_pct)\n",
    "valid_ds, test_ds = train_test_split(test_ds, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTCK-1C1D3CJ"
   },
   "source": [
    "### Encoding the data for BERTSUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjEqB-wCD3CK"
   },
   "source": [
    "Let's look at how we would conventionally encode text and pass it to BERT. Here is an example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzkS-12OD3CM"
   },
   "outputs": [],
   "source": [
    "sentence1 = \"My name is Henry.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfagCGg0D3CP"
   },
   "source": [
    "We will start off by getting the BertTokenizer from the Transformers repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d8d792ce323241b7bf51af328f6990f0"
     ]
    },
    "colab_type": "code",
    "id": "gF2IIHNxD3CQ",
    "outputId": "a826b317-c73e-4d0b-e3d3-51349e240dac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fe20a16bd84e139c152cbcf1f01b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WooDFosD3CU"
   },
   "source": [
    "Tokenizers from this repo have a few methods we can use. The first, _tokenize()_, will break up a string into Bert style tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdvZLKnsD3CV",
    "outputId": "b2c7d997-2da3-43d6-8965-84cdae3f5e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'name', 'is', 'henry', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeized_text = tokenizer.tokenize(sentence1)\n",
    "tokeized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6L8w5KUD3CY"
   },
   "source": [
    "The second, _convert_tokens_to_ids()_, will convert these tokens to their numerical equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofl1b0eED3CZ",
    "outputId": "78878b7a-5105-4a86-da54-d13583ec2c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2026, 2171, 2003, 2888, 1012]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_tokens = tokenizer.convert_tokens_to_ids(tokeized_text)\n",
    "numerical_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo7uOWNsD3Cc"
   },
   "source": [
    "We can reverse this by calling _decode()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJFWu5LtD3Cd",
    "outputId": "df6721b1-f8ef-4ea3-bcd4-a1d20b1dbb44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is henry.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(numerical_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIjIDZCmD3Cg"
   },
   "source": [
    "Remember though: when we pass text to Bert, we should also pass a [CLS] token at the start of the first sentence and [SEP] tokens at the end of each sentence. Fortunately there is another method, _encode()_, that takes care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yoluaZmD3Ch",
    "outputId": "431f5977-f3a4-4eef-9e2f-258f2ddec60f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2026, 2171, 2003, 2888, 1012, 102]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(sentence1)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3zVFPY-D3Ck"
   },
   "source": [
    "If we call _decode()_ on this, we get those tokens as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pV_OsqXD3Ck",
    "outputId": "30fe372f-ad26-42d9-88e9-147ca4234b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] my name is henry. [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8eitNGkD3Cp"
   },
   "source": [
    "To pass this sentence to Bert, we can just grab? the pretrained model using the Transformers API, convert our encoded text to a tensor, and pass it to the model as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9faedbf0789048d384527f2a9dbb60e1",
      "df27537cf8aa4e52afda09ab8b30a591"
     ]
    },
    "colab_type": "code",
    "id": "RK0uexCED3Cp",
    "outputId": "183ad6ae-5224-4b9d-827f-b261b0ae1da8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46dc70458fcc450fb27afbac1d04d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8481640ad90b4396a586560b4ba6f7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0131,  0.5101, -0.4724,  ...,  0.0022,  0.1581,  0.7128],\n",
       "          [ 0.0465,  0.1645, -0.4436,  ..., -0.1006,  0.1616,  0.7363],\n",
       "          [-0.2963,  0.4691, -0.0759,  ..., -0.3669,  0.2876,  0.3649],\n",
       "          ...,\n",
       "          [ 0.4391, -0.3440, -0.2106,  ...,  0.0676,  0.3720,  0.7365],\n",
       "          [ 0.3724, -0.2132, -0.3207,  ...,  0.2093, -0.0429, -0.5615],\n",
       "          [ 0.9395, -0.1101, -0.0936,  ...,  0.3332, -0.5686, -0.2744]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.9331, -0.5581, -0.9425,  0.8893,  0.8785, -0.2383,  0.9064,  0.3685,\n",
       "          -0.8970, -1.0000, -0.7138,  0.9930,  0.9863,  0.6877,  0.9614, -0.8641,\n",
       "          -0.5556, -0.6808,  0.4099, -0.3153,  0.7553,  1.0000, -0.1938,  0.5261,\n",
       "           0.5817,  0.9987, -0.8773,  0.9546,  0.9767,  0.7685, -0.6838,  0.3427,\n",
       "          -0.9953, -0.1891, -0.9334, -0.9904,  0.6037, -0.7324, -0.1873,  0.0403,\n",
       "          -0.9549,  0.4333,  1.0000, -0.2624,  0.6050, -0.4379, -1.0000,  0.4733,\n",
       "          -0.9188,  0.9807,  0.9437,  0.9715,  0.3891,  0.5452,  0.6936, -0.4950,\n",
       "           0.0306,  0.2147, -0.3955, -0.6541, -0.7305,  0.5845, -0.9514, -0.8613,\n",
       "           0.9725,  0.8788, -0.4316, -0.4007, -0.1265,  0.0706,  0.9289,  0.1947,\n",
       "          -0.3514, -0.8952,  0.7412,  0.3585, -0.7243,  1.0000, -0.7075, -0.9893,\n",
       "           0.9050,  0.8263,  0.6510, -0.5113,  0.5691, -1.0000,  0.6965, -0.1047,\n",
       "          -0.9943,  0.4741,  0.7290, -0.4832,  0.6584,  0.7177, -0.5328, -0.6702,\n",
       "          -0.5867, -0.9002, -0.4121, -0.4322,  0.2225, -0.3233, -0.6335, -0.5184,\n",
       "           0.5308, -0.7145, -0.5903,  0.6906,  0.4476,  0.7126,  0.5418, -0.5434,\n",
       "           0.5876, -0.9681,  0.7701, -0.5021, -0.9923, -0.6821, -0.9930,  0.7753,\n",
       "          -0.5694, -0.1839,  0.9779, -0.3568,  0.5652, -0.2361, -0.9780, -1.0000,\n",
       "          -0.8131, -0.6810, -0.4515, -0.5275, -0.9847, -0.9846,  0.6866,  0.9747,\n",
       "           0.3576,  0.9999, -0.4410,  0.9618, -0.5448, -0.8161,  0.8473, -0.6638,\n",
       "           0.8438,  0.4737, -0.5843,  0.4195, -0.7308,  0.6338, -0.8674, -0.3747,\n",
       "          -0.8749, -0.9513, -0.5159,  0.9637, -0.6989, -0.9806, -0.1626, -0.3741,\n",
       "          -0.6439,  0.8252,  0.8720,  0.5242, -0.5393,  0.5828,  0.2522,  0.7153,\n",
       "          -0.8889, -0.4185,  0.5396, -0.4568, -0.9196, -0.9870, -0.4895,  0.5729,\n",
       "           0.9942,  0.8082,  0.4343,  0.8978, -0.4896,  0.8609, -0.9718,  0.9882,\n",
       "          -0.2561,  0.5128, -0.7872,  0.2849, -0.9206,  0.1276,  0.8634, -0.8648,\n",
       "          -0.8744, -0.3864, -0.6455, -0.5129, -0.9117,  0.4763, -0.3245, -0.4870,\n",
       "          -0.2284,  0.9632,  0.9716,  0.8262,  0.4452,  0.7092, -0.9261, -0.7103,\n",
       "           0.2439,  0.3289,  0.1958,  0.9963, -0.7335, -0.1189, -0.9617, -0.9905,\n",
       "           0.0073, -0.9451, -0.3958, -0.8201,  0.8424, -0.6087,  0.7246,  0.6475,\n",
       "          -0.9860, -0.8226,  0.5900, -0.6307,  0.5345, -0.5040,  0.9563,  0.9698,\n",
       "          -0.7619,  0.6636,  0.9587, -0.9640, -0.8658,  0.7673, -0.4550,  0.9097,\n",
       "          -0.7625,  0.9788,  0.9846,  0.9209, -0.9204, -0.8166, -0.8463, -0.7605,\n",
       "          -0.1970,  0.2916,  0.9547,  0.7771,  0.5661,  0.3823, -0.7394,  0.9982,\n",
       "          -0.9534, -0.9724, -0.4775, -0.3768, -0.9933,  0.8827,  0.3272,  0.7387,\n",
       "          -0.5694, -0.7421, -0.9779,  0.8498,  0.3360,  0.9833, -0.5886, -0.9364,\n",
       "          -0.7453, -0.9577,  0.1021, -0.3464, -0.6553,  0.0829, -0.9712,  0.6061,\n",
       "           0.6983,  0.7098, -0.8572,  0.9994,  1.0000,  0.9861,  0.9154,  0.8884,\n",
       "          -1.0000, -0.6742,  1.0000, -0.9987, -1.0000, -0.9415, -0.7852,  0.6688,\n",
       "          -1.0000, -0.3661, -0.1063, -0.9304,  0.7710,  0.9790,  0.9936, -1.0000,\n",
       "           0.7208,  0.9578, -0.7298,  0.9947, -0.5818,  0.9735,  0.6821,  0.5195,\n",
       "          -0.3293,  0.4810, -0.9652, -0.8902, -0.6979, -0.8576,  0.9998,  0.2113,\n",
       "          -0.7642, -0.9162,  0.7419, -0.2739, -0.1403, -0.9808, -0.4479,  0.6720,\n",
       "           0.9103,  0.3200,  0.4689, -0.6990,  0.3290,  0.2308,  0.1588,  0.7703,\n",
       "          -0.9245, -0.5876, -0.3337, -0.2038, -0.6994, -0.9836,  0.9789, -0.4192,\n",
       "           0.9562,  1.0000,  0.1991, -0.9178,  0.8133,  0.4944, -0.5992,  1.0000,\n",
       "           0.8932, -0.9848, -0.6801,  0.6695, -0.6961, -0.8098,  0.9995, -0.3705,\n",
       "          -0.8737, -0.7852,  0.9908, -0.9940,  0.9993, -0.9512, -0.9857,  0.9756,\n",
       "           0.9650, -0.7953, -0.6192,  0.1607, -0.7460,  0.3640, -0.9359,  0.8155,\n",
       "           0.6832, -0.2825,  0.9296, -0.8821, -0.7427,  0.4023, -0.7408, -0.1706,\n",
       "           0.9631,  0.6418, -0.3488,  0.1853, -0.3682, -0.8815, -0.9839,  0.7883,\n",
       "           1.0000, -0.3712,  0.9392, -0.4914, -0.1864,  0.0863,  0.6069,  0.7213,\n",
       "          -0.5092, -0.8423,  0.8985, -0.9783, -0.9923,  0.7070,  0.3444, -0.3751,\n",
       "           1.0000,  0.5284,  0.3632,  0.4367,  0.9976,  0.1034,  0.5191,  0.9308,\n",
       "           0.9914, -0.3216,  0.6938,  0.8678, -0.9635, -0.5136, -0.7837,  0.1295,\n",
       "          -0.9477, -0.1008, -0.9666,  0.9809,  0.9813,  0.6007,  0.3587,  0.8969,\n",
       "           1.0000, -0.7891,  0.5964,  0.0385,  0.7626, -1.0000, -0.8903, -0.5192,\n",
       "          -0.3201, -0.9128, -0.5730,  0.4217, -0.9759,  0.9259,  0.8130, -0.9941,\n",
       "          -0.9898, -0.4212,  0.9004,  0.2032, -0.9979, -0.8470, -0.7222,  0.8649,\n",
       "          -0.4087, -0.9541, -0.4647, -0.5678,  0.5834, -0.2581,  0.6865,  0.9260,\n",
       "           0.6892, -0.8349, -0.3492, -0.1078, -0.8602,  0.9286, -0.8133, -0.9802,\n",
       "          -0.4247,  1.0000, -0.6425,  0.9432,  0.7428,  0.7505, -0.2929,  0.4608,\n",
       "           0.9421,  0.4458, -0.7743, -0.9559, -0.1003, -0.5343,  0.8223,  0.7268,\n",
       "           0.8166,  0.8760,  0.8992,  0.2685, -0.1973,  0.2124,  0.9998, -0.2420,\n",
       "          -0.1062, -0.4636, -0.2324, -0.5566, -0.2581,  1.0000,  0.3840,  0.5130,\n",
       "          -0.9936, -0.9630, -0.9174,  1.0000,  0.8985, -0.6463,  0.7740,  0.7161,\n",
       "          -0.4042,  0.8289, -0.2965, -0.4088,  0.4347,  0.2853,  0.9722, -0.7575,\n",
       "          -0.9846, -0.6010,  0.6289, -0.9823,  1.0000, -0.6981, -0.4530, -0.6179,\n",
       "          -0.5769, -0.4102, -0.0814, -0.9899, -0.4321,  0.4373,  0.9784,  0.4370,\n",
       "          -0.6692, -0.9277,  0.9232,  0.8740, -0.9710, -0.9471,  0.9683, -0.9883,\n",
       "           0.7759,  1.0000,  0.6190,  0.4416,  0.4544, -0.5544,  0.4926, -0.0632,\n",
       "           0.8523, -0.9705, -0.5362, -0.3663,  0.3286, -0.3028, -0.2342,  0.7115,\n",
       "           0.4406, -0.6540, -0.7624, -0.2965,  0.4844,  0.8713, -0.3848, -0.2723,\n",
       "           0.3142, -0.3762, -0.9402, -0.4402, -0.6127, -1.0000,  0.7521, -1.0000,\n",
       "           0.6548,  0.3787, -0.3914,  0.8428,  0.7064,  0.7979, -0.8245, -0.9523,\n",
       "           0.2509,  0.8296, -0.4623, -0.7238, -0.7576,  0.4070, -0.2906,  0.2850,\n",
       "          -0.7912,  0.7958, -0.4721,  1.0000,  0.3037, -0.8389, -0.9813,  0.2342,\n",
       "          -0.4474,  1.0000, -0.9204, -0.9676,  0.5581, -0.8937, -0.8554,  0.4932,\n",
       "           0.1740, -0.8655, -0.9820,  0.9727,  0.7954, -0.6726,  0.6186, -0.4475,\n",
       "          -0.7197,  0.1459,  0.9398,  0.9929,  0.6815,  0.9417,  0.1003, -0.5024,\n",
       "           0.9878,  0.3608, -0.0091,  0.2223,  1.0000,  0.4851, -0.9459, -0.0478,\n",
       "          -0.9849, -0.3835, -0.9436,  0.4284,  0.4341,  0.9448, -0.3590,  0.9672,\n",
       "          -0.9107,  0.1345, -0.7903, -0.7883,  0.5019, -0.9452, -0.9920, -0.9864,\n",
       "           0.7309, -0.5388, -0.1663,  0.3784,  0.2110,  0.6243,  0.5057, -1.0000,\n",
       "           0.9529,  0.6126,  0.9556,  0.9764,  0.7873,  0.6124,  0.4118, -0.9914,\n",
       "          -0.9886, -0.4676, -0.3931,  0.7929,  0.7347,  0.9261,  0.6229, -0.6094,\n",
       "          -0.6415, -0.7592, -0.8402, -0.9949,  0.6714, -0.7481, -0.9523,  0.9762,\n",
       "          -0.4146, -0.3842, -0.3130, -0.9094,  0.8726,  0.7707,  0.3027,  0.1920,\n",
       "           0.5548,  0.8707,  0.9267,  0.9836, -0.9189,  0.7609, -0.8888,  0.5722,\n",
       "           0.8477, -0.9430,  0.3414,  0.6346, -0.4661,  0.3986, -0.3853, -0.9734,\n",
       "           0.4998, -0.4716,  0.7436, -0.5374, -0.0366, -0.5376, -0.2881, -0.7713,\n",
       "          -0.8864,  0.7493,  0.6999,  0.9281,  0.9318, -0.2077, -0.8275, -0.2421,\n",
       "          -0.8836, -0.9408,  0.9298, -0.1580, -0.4070,  0.8775,  0.0822,  0.9180,\n",
       "           0.3278, -0.4708, -0.4402, -0.7994,  0.8596, -0.7428, -0.6764, -0.7684,\n",
       "           0.7380,  0.5363,  1.0000, -0.8607, -0.9562, -0.6424, -0.5842,  0.6140,\n",
       "          -0.6882, -1.0000,  0.5454, -0.6090,  0.8294, -0.8904,  0.8970, -0.8605,\n",
       "          -0.9823, -0.4458,  0.6957,  0.8966, -0.6579, -0.7831,  0.6824, -0.6362,\n",
       "           0.9941,  0.8847, -0.7817,  0.2377,  0.7736, -0.9510, -0.8020,  0.9463]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "text_tensor = torch.tensor([encoded_text])\n",
    "model(text_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xD_7TAGeD3Ct"
   },
   "source": [
    "That was easy! Let's do the same thing but with a pair of sentences now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-6OId-6D3Cv"
   },
   "outputs": [],
   "source": [
    "sentence2 = \"What is yours?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FjPcdh_ZD3Cy"
   },
   "source": [
    "We can pass both sentences to the tokenizer as a pair of arguments. Notice how it prepends the [CLS] token (encoded as 101) to the start of the first sentence and adds the [SEP] token (encoded as 102) to the end of both sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaoWtpc9D3Cz",
    "outputId": "92d981ec-4c27-40fc-ee7a-551575776582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2026, 2171, 2003, 2888, 1012,  102, 2054, 2003, 6737, 1029,  102]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(sentence1, sentence2)\n",
    "text_tensor = torch.tensor([encoded_text])\n",
    "text_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwtVWN__D3C2"
   },
   "source": [
    "Now we have multiple sentences, there is another aspect we need to consider. Bert actually takes more than just the encoded text as input. It also takes segment embeddings which tell it when one sentence ends and the other begins. These embeddings take the value 0 for the first sentence and 1 for the second sentence. Since we only passed one sentence to model last time, we didn't have to consider this. Behind the scenes, the Transformers library did something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HX17sW5SD3C3",
    "outputId": "b20443a5-3136-4c28-fb12-13421e258157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "old_encoded_text = tokenizer.encode(sentence1)\n",
    "segments_ids = [0] * len(old_encoded_text)\n",
    "print(segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CafAtPXID3C6"
   },
   "source": [
    "These segment embeddings were passed to the model as a tensor along with our text tensor. Lets write a function which will assign segment embeddings of 0 to the first sentence and then, when it hits the [SEP] token value of 102, switch to assigning segment embeddings of 1 for the second sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5njdevyD3C7"
   },
   "outputs": [],
   "source": [
    "def create_seg_embs(encoded_text, sent_sep_token_id):\n",
    "    segment_embeddings = []\n",
    "    sentence_num = 0 \n",
    "    for item in encoded_text:\n",
    "        segment_embeddings.append(sentence_num % 2)\n",
    "        if item == sent_sep_token_id:\n",
    "            sentence_num += 1\n",
    "            \n",
    "    return torch.tensor([segment_embeddings]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpL2KUVQD3C-",
    "outputId": "230f6934-51d4-4a75-8f5c-8a2f60e40d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_tensor = create_seg_embs(encoded_text, 102)\n",
    "segments_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pa1YXcK2D3DB"
   },
   "source": [
    "Now we can pass our sentence pairs to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fICsHIYD3DC",
    "outputId": "4a084126-4534-44da-8d12-e1210570fe2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1613,  0.0970, -0.0204,  ..., -0.2197, -0.0483,  0.2055],\n",
       "          [ 0.0190,  0.4391, -0.0785,  ...,  0.1633, -0.1503, -0.2627],\n",
       "          [ 0.1489, -0.3272,  0.5559,  ..., -0.5613,  0.0607, -0.5971],\n",
       "          ...,\n",
       "          [ 0.8725, -0.0923,  0.1296,  ..., -0.1749, -0.4230, -0.6996],\n",
       "          [-0.2305, -0.2320, -0.6867,  ..., -0.0152,  0.1282, -0.3187],\n",
       "          [ 0.7634, -0.1366, -0.4033,  ...,  0.1599, -0.6937, -0.5200]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.8205, -0.1513,  0.2832,  0.6705, -0.3516, -0.0274,  0.7660,  0.2596,\n",
       "           0.3649, -0.9997,  0.0634,  0.2758,  0.9832, -0.1598,  0.9094, -0.4175,\n",
       "          -0.0640, -0.5751,  0.2379, -0.4605,  0.5924,  0.9564,  0.5097,  0.2164,\n",
       "           0.3257,  0.4052, -0.6240,  0.9276,  0.9637,  0.7216, -0.5290,  0.0292,\n",
       "          -0.9891, -0.0566, -0.1457, -0.9885,  0.1350, -0.6914,  0.0132,  0.0829,\n",
       "          -0.8447,  0.0689,  0.9979, -0.1428,  0.1553, -0.2703, -0.9998,  0.2237,\n",
       "          -0.8825, -0.1750, -0.0609, -0.3918,  0.0085,  0.2952,  0.3098,  0.2155,\n",
       "          -0.1378,  0.1858, -0.1944, -0.3810, -0.5606,  0.4042, -0.1118, -0.8354,\n",
       "          -0.3198, -0.2758, -0.0975, -0.0904,  0.0605, -0.0170,  0.7209,  0.1867,\n",
       "           0.3777, -0.8187, -0.4557,  0.2168, -0.5022,  1.0000, -0.4110, -0.9740,\n",
       "          -0.2600, -0.2244,  0.3604,  0.6726, -0.4429, -1.0000,  0.1923,  0.0325,\n",
       "          -0.9883,  0.1681,  0.1903, -0.0972, -0.4208,  0.4059, -0.0855, -0.1573,\n",
       "          -0.0292,  0.1395, -0.1647, -0.0018,  0.0401, -0.1517, -0.0778, -0.3390,\n",
       "           0.2648, -0.2796, -0.4048,  0.2502, -0.5180,  0.5795,  0.2216, -0.2019,\n",
       "           0.3141, -0.9492,  0.5269, -0.2367, -0.9853, -0.4130, -0.9820,  0.6394,\n",
       "           0.1240, -0.1421,  0.9488,  0.5019,  0.3305, -0.0468,  0.2417, -1.0000,\n",
       "          -0.1297, -0.4141,  0.2757, -0.1804, -0.9776, -0.9625,  0.5520,  0.9362,\n",
       "           0.0980,  0.9961, -0.2540,  0.9391,  0.3334, -0.1892, -0.3407, -0.3613,\n",
       "           0.4532,  0.1809, -0.3820,  0.1569, -0.0610,  0.0181, -0.0784, -0.1482,\n",
       "           0.1917, -0.9295, -0.3778,  0.9456,  0.0928,  0.1018,  0.6693, -0.1913,\n",
       "          -0.2092,  0.7706,  0.2161,  0.3008, -0.0158,  0.2197, -0.4626,  0.3872,\n",
       "          -0.7943,  0.3581,  0.3264, -0.1672, -0.0307, -0.9710, -0.2316,  0.3933,\n",
       "           0.9894,  0.7235,  0.1935, -0.1023, -0.1365,  0.1758, -0.9570,  0.9764,\n",
       "          -0.0953,  0.3084,  0.2826, -0.4099, -0.8391, -0.3273,  0.6667,  0.2266,\n",
       "          -0.7706,  0.0393, -0.4448, -0.3252, -0.1101,  0.3082, -0.1933, -0.3330,\n",
       "           0.0133,  0.9091,  0.8930,  0.6466, -0.5753,  0.5285, -0.8006, -0.4571,\n",
       "           0.0738,  0.3105,  0.0585,  0.9912, -0.0897,  0.0335, -0.9172, -0.9838,\n",
       "           0.0201, -0.9044,  0.1019, -0.4199,  0.4041,  0.6052, -0.4389,  0.4371,\n",
       "          -0.9046, -0.7809,  0.3042, -0.4646,  0.3140, -0.2681,  0.3939,  0.0981,\n",
       "          -0.4305,  0.6169,  0.9069,  0.2684, -0.7046,  0.6550, -0.2096,  0.7745,\n",
       "          -0.5215,  0.9306,  0.1662,  0.1534, -0.9224,  0.1829, -0.6962,  0.2657,\n",
       "           0.0022, -0.6667, -0.3563,  0.3894,  0.1869,  0.7982, -0.4577,  0.9688,\n",
       "          -0.3764, -0.9593,  0.1440,  0.1385, -0.9898, -0.0429,  0.3617, -0.4927,\n",
       "          -0.2370, -0.4580, -0.9556,  0.6400,  0.1722,  0.9349,  0.1971, -0.8383,\n",
       "          -0.1039, -0.9246, -0.1408, -0.0650,  0.6713, -0.1546, -0.9438,  0.4425,\n",
       "           0.5378,  0.3508,  0.4284,  0.9854,  0.9991,  0.9688,  0.8664,  0.7613,\n",
       "          -0.9043, -0.1014,  0.9999, -0.5128, -1.0000, -0.9157, -0.1471,  0.1965,\n",
       "          -1.0000, -0.1609, -0.0839, -0.9146, -0.1647,  0.9738,  0.9401, -1.0000,\n",
       "           0.7727,  0.9134, -0.5549,  0.2876, -0.2107,  0.9645,  0.2111,  0.2255,\n",
       "          -0.1409,  0.2794, -0.2091, -0.7408,  0.3293,  0.1881,  0.5670,  0.1106,\n",
       "          -0.6350, -0.8638, -0.0200, -0.0342, -0.3309, -0.9536, -0.0576, -0.1946,\n",
       "           0.6094,  0.0071,  0.1878, -0.6156,  0.0875, -0.5552,  0.0867,  0.5745,\n",
       "          -0.9157, -0.2865,  0.1265, -0.5126,  0.3092, -0.9555,  0.9507, -0.2529,\n",
       "          -0.0262,  1.0000, -0.0637, -0.7850,  0.3101,  0.0993, -0.3150,  1.0000,\n",
       "           0.5090, -0.9775, -0.3841,  0.2429, -0.2812, -0.3441,  0.9970, -0.1291,\n",
       "           0.4151,  0.5135,  0.9806, -0.9911,  0.4662, -0.8798, -0.9713,  0.9489,\n",
       "           0.9317, -0.1080, -0.5089,  0.0712,  0.0473,  0.1085, -0.8709,  0.2860,\n",
       "           0.4564, -0.2451,  0.8708, -0.6292, -0.3767,  0.1971,  0.2111,  0.5398,\n",
       "           0.0951,  0.3348, -0.2354, -0.0634, -0.1655, -0.2415, -0.9702, -0.0498,\n",
       "           1.0000,  0.1504, -0.3362,  0.1797, -0.0174, -0.3493,  0.2603,  0.3522,\n",
       "          -0.2799, -0.7629,  0.0741, -0.8288, -0.9851,  0.6666,  0.1171, -0.2962,\n",
       "           0.9977, -0.0034,  0.1004, -0.3816,  0.2531, -0.0787,  0.3246, -0.2756,\n",
       "           0.9810, -0.2749,  0.3997,  0.5630,  0.1684, -0.3060, -0.5482, -0.1209,\n",
       "          -0.9116,  0.0764, -0.9315,  0.9622, -0.0435,  0.2982,  0.1768,  0.0498,\n",
       "           1.0000, -0.3585,  0.3324,  0.0514,  0.6499, -0.8365, -0.6818, -0.1871,\n",
       "           0.0249,  0.3911, -0.0925,  0.2616, -0.9590, -0.2574,  0.0463, -0.9379,\n",
       "          -0.9902,  0.5257,  0.5834,  0.1702, -0.4522, -0.4796, -0.5818, -0.0262,\n",
       "          -0.1720, -0.9337,  0.5290, -0.3064,  0.2393, -0.2331,  0.4172, -0.3365,\n",
       "           0.8536,  0.3365,  0.3131, -0.0100, -0.7293,  0.6379, -0.6913,  0.0105,\n",
       "          -0.1561,  1.0000, -0.4143,  0.0380,  0.6683,  0.4540, -0.1510,  0.2706,\n",
       "           0.0081,  0.2211,  0.3600,  0.3640, -0.4085, -0.3309,  0.5503, -0.3778,\n",
       "          -0.2178,  0.7635, -0.0199, -0.0652, -0.0074, -0.1106,  0.9899,  0.0116,\n",
       "           0.1212, -0.2517, -0.0446, -0.1890, -0.0933,  1.0000,  0.2159, -0.1170,\n",
       "          -0.9901,  0.2069, -0.8172,  0.9966,  0.8080, -0.6490,  0.4616,  0.3262,\n",
       "          -0.0782,  0.5499, -0.1271, -0.2293,  0.1988,  0.1649,  0.9585, -0.3311,\n",
       "          -0.9708, -0.4620,  0.2020, -0.9589,  0.9313, -0.2964, -0.2173, -0.2807,\n",
       "           0.4247,  0.0571, -0.2003, -0.9817, -0.2111,  0.0736,  0.9456,  0.2080,\n",
       "          -0.4897, -0.8669, -0.5048, -0.1648,  0.1132, -0.9410,  0.9669, -0.9741,\n",
       "           0.3581,  1.0000,  0.3095, -0.7079,  0.0937, -0.3281,  0.0927,  0.3479,\n",
       "           0.5435, -0.9366, -0.1474,  0.0874,  0.2021, -0.0694,  0.1741,  0.7296,\n",
       "           0.1479, -0.4035, -0.4249,  0.0507,  0.3134,  0.6880, -0.2477, -0.1124,\n",
       "           0.1054,  0.0364, -0.8681, -0.1100, -0.2609, -0.9820,  0.6554, -1.0000,\n",
       "          -0.3073, -0.5806, -0.3776,  0.8414, -0.1469,  0.1729, -0.7924,  0.3737,\n",
       "           0.8736,  0.7509, -0.1732,  0.1925, -0.7894,  0.0227,  0.0652,  0.0122,\n",
       "          -0.0055,  0.7292, -0.0480,  1.0000,  0.0116, -0.4449, -0.8821,  0.1203,\n",
       "          -0.2033,  0.9995, -0.7596, -0.9405,  0.2521, -0.2227, -0.8228,  0.2496,\n",
       "           0.0400, -0.3705,  0.0635,  0.9195,  0.6996, -0.3998,  0.3247, -0.2868,\n",
       "          -0.1635,  0.0309, -0.2990,  0.9865,  0.1839,  0.7816,  0.6804, -0.0354,\n",
       "           0.9645,  0.1584,  0.3932,  0.1038,  1.0000,  0.2786, -0.8674,  0.4212,\n",
       "          -0.9553, -0.1895, -0.8896,  0.1876,  0.0820,  0.8491, -0.0428,  0.9634,\n",
       "           0.3563, -0.0645,  0.0937,  0.5405,  0.4226, -0.9073, -0.9835, -0.9899,\n",
       "           0.0477, -0.3900, -0.0099,  0.0999,  0.1224,  0.3158,  0.2231, -1.0000,\n",
       "           0.9206,  0.2917,  0.0303,  0.9541,  0.0669,  0.2111,  0.2170, -0.9852,\n",
       "          -0.8855, -0.1706, -0.2265,  0.6890,  0.4665,  0.8560,  0.2901, -0.4925,\n",
       "           0.2161,  0.2486,  0.0620, -0.9911,  0.2910,  0.4768, -0.8751,  0.9618,\n",
       "          -0.6731, -0.2826,  0.6839, -0.0148,  0.7619,  0.5547,  0.2629,  0.0664,\n",
       "           0.4058,  0.8645,  0.9062,  0.9884,  0.0358,  0.7557,  0.2839,  0.3031,\n",
       "           0.7035, -0.9227, -0.0376,  0.1399, -0.2295,  0.3054, -0.0965, -0.8289,\n",
       "           0.8428, -0.3036,  0.2702, -0.3444,  0.1196, -0.3819, -0.1891, -0.6887,\n",
       "          -0.2078,  0.5004,  0.2792,  0.8778, -0.0648,  0.1102, -0.4656, -0.0481,\n",
       "           0.3187, -0.9327,  0.7729,  0.0087,  0.4673, -0.1830, -0.1201,  0.7876,\n",
       "          -0.5288, -0.3014, -0.1533, -0.5849,  0.7469, -0.2417, -0.3936, -0.3623,\n",
       "           0.5237,  0.2991,  0.9763,  0.2594,  0.2565, -0.0738, -0.1954,  0.3397,\n",
       "          -0.3445, -1.0000,  0.3760,  0.4295,  0.0389,  0.0773, -0.1959,  0.0062,\n",
       "          -0.9266, -0.1526, -0.1758, -0.2298, -0.4244, -0.1259,  0.4970,  0.4648,\n",
       "           0.1140,  0.8360, -0.3734,  0.7984,  0.4553,  0.1743, -0.6361,  0.8590]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(text_tensor, segments_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Azpq1e-D3DF"
   },
   "source": [
    "So far this hasn't been too bad but let's go off-piste a litle. It's not actually possible to pass a third sentence to Bert in the way we passed the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57myEPl1D3DG"
   },
   "outputs": [],
   "source": [
    "sentence3 = \"Can you hear me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2l8MkAeTD3DI",
    "outputId": "b2e2baee-7d59-40aa-db81-a9c192c24a32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2026, 2171, 2003, 2888, 1012,  102, 2054, 2003, 6737, 1029,  102]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_text = tokenizer.encode(sentence1, sentence2, sentence3)\n",
    "text_tensor = torch.tensor([broken_text])\n",
    "text_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjT0KKLID3DL"
   },
   "source": [
    "See how it only picked up the first two sentences. How can we get around this? One option would be to pass multiple sentences as a single string. e.g. `\"My name is Henry. What is yours? Can you hear me?\"` This might work. But remember, that wasn't how BERT was trained. It's used to seeing one sentence at a time matched with one set of segment embeddings. It is also likely to result in inputs longer than 512 tokens, which we will have to truncate, since Bert won't be able to handle them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ad2B0xsD3DM"
   },
   "source": [
    "### BertSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qphQB1f7D3DM"
   },
   "source": [
    "This is where we begin to introduce ideas from the paper. The authors adapt the Bert encoder like so:\n",
    "![](bertabs_img.png) \n",
    "Firstly, they insert [CLS] tokens at the start of each sentence. Not just the first one. And secondly, they alternate the values of the segment embeddings with each new sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axKv2R-2D3DN"
   },
   "source": [
    "So let's give it a go. The existing _encode()_ function is actually all we need. We just need to make sure we pass our data as a list, where every sentence is a seperate item. This is the way the CNN/DM dataset is formatted, and consequently the format I have chosen for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBUXs5RgD3DO"
   },
   "outputs": [],
   "source": [
    "long_text = [\"My name is Henry.\", \"What is yours?\", \"Can you hear me?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qx2zmXSHD3DQ",
    "outputId": "0c1a6127-ea47-4c4e-f2c3-9a92c555a0d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 2026, 2171, 2003, 2888, 1012, 102],\n",
       " [101, 2054, 2003, 6737, 1029, 102],\n",
       " [101, 2064, 2017, 2963, 2033, 1029, 102]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflat = [tokenizer.encode(s) for s in long_text]\n",
    "unflat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9EKlX1CD3DU"
   },
   "source": [
    "Now all have to do is flatten this list of lists. Notice how the 102s end each sentence and the 101s now start them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMefVwQQD3DU",
    "outputId": "0cb72229-fbf3-4631-9206-410fda5d2c6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2026,\n",
       " 2171,\n",
       " 2003,\n",
       " 2888,\n",
       " 1012,\n",
       " 102,\n",
       " 101,\n",
       " 2054,\n",
       " 2003,\n",
       " 6737,\n",
       " 1029,\n",
       " 102,\n",
       " 101,\n",
       " 2064,\n",
       " 2017,\n",
       " 2963,\n",
       " 2033,\n",
       " 1029,\n",
       " 102]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = [item for sublist in unflat for item in sublist]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMsBIzipD3DX"
   },
   "source": [
    "(By the way, I've been writing Python for about two years now and I still have get that one liner off Stack Overflow every time I need it...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkRtTUC3D3DY"
   },
   "source": [
    "Let's take this opportunity to create our segment embeddings as well. We can use the function we wrote earlier for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmrtUYrMD3DZ",
    "outputId": "d02263d9-1b1c-465a-de3c-bbfacc55a250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_embs = create_seg_embs(flat_list, tokenizer.sep_token_id)\n",
    "seg_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgJSmKGMD3Dc"
   },
   "source": [
    "We've now successfully encoded our text, inserted [CLS] tokens at the start of each sentence, and created corresponding segment embeddings. Now we need to add some padding so that, when we pass these articles in batches, their sequence length will be the same. But first, we will declare a maximum sequence length, which in this case will be 512. Anything longer than this will be truncated. However, we don't want to truncate in the middle of a sentence. We therefore find all the [SEP] tokens in the article, since these always come at the end of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4jVkSx4D3Di",
    "outputId": "36c3c581-1903-4689-f911-ded10fc82727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 12, 19]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_sep_idxs = [idx for idx, t in enumerate(flat_list) if t == tokenizer.sep_token_id and idx < 512]\n",
    "sent_sep_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7ueBFDyD3Dl"
   },
   "source": [
    "Now we truncate the text so it stops at the end of the last sentence contained in the first 512 tokens. We do this unless we somehow are faced with a single sentence longer than 512 words, in which case we will have to cut off our gushing author mid-flow. Probably best for all concerned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUkiuIUrD3Dl",
    "outputId": "1d669c56-989f-4799-987a-4d66f29672db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sent_sep_idx = min(max(sent_sep_idxs)+1 if (len(sent_sep_idxs) > 0) else 512, 512)\n",
    "last_sent_sep_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7l7UiIjD3Dn"
   },
   "source": [
    "As you can {{see, this particular example is unaffected by our maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHUx6N8uD3Do",
    "outputId": "7de39080-a3e0-4686-8ea9-99c590a27cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2026,\n",
       " 2171,\n",
       " 2003,\n",
       " 2888,\n",
       " 1012,\n",
       " 102,\n",
       " 101,\n",
       " 2054,\n",
       " 2003,\n",
       " 6737,\n",
       " 1029,\n",
       " 102,\n",
       " 101,\n",
       " 2064,\n",
       " 2017,\n",
       " 2963,\n",
       " 2033,\n",
       " 1029,\n",
       " 102]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = flat_list[:last_sent_sep_idx]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrRzPXwED3Dr"
   },
   "source": [
    "Now we will pad to the right with zeros to bring the sequence length up to 512. \n",
    "\n",
    "We'll also convert our padded list to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OvMYw-1D3Ds",
    "outputId": "66c57876-e683-46e8-be6a-38e336a5f84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2026, 2171, 2003, 2888, 1012,  102,  101, 2054, 2003, 6737, 1029,\n",
       "          102,  101, 2064, 2017, 2963, 2033, 1029,  102,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_list = flat_list + [tokenizer.pad_token_id] * (512 - len(flat_list))\n",
    "padded_tensor = torch.tensor([padded_list])\n",
    "print(padded_tensor.shape)\n",
    "padded_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPAxGozMD3Du"
   },
   "source": [
    "Our segment embeddings are already a tensor, so we'll use Pytorch's _torch.nn.functional.pad()_ method instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWneKr9PD3Dv",
    "outputId": "0685eb9a-3d8b-48e0-93f5-b1b1a6f6ff15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seg = F.pad(input=seg_embs, pad=(0,512-seg_embs.shape[1]), mode='constant', value=tokenizer.pad_token_id)\n",
    "padded_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LqhWrvPD3Dx"
   },
   "source": [
    "So we now have correctly sized inputs. But we don't want this padding to warp the results of our model. We therefore need to give the model a third tensor, an attention mask. This will be similar to the segment embeddings. It will have a value of 1 at the indices that correspond to actual content we want the model to attend to, and 0 whereever there is just padding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nzLjpgrD3Dy",
    "outputId": "572f6a96-3b8b-4ac5-f193-bba3281ad8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask = torch.zeros_like(padded_tensor)\n",
    "src_mask[padded_tensor != tokenizer.pad_token_id] = 1 \n",
    "print(src_mask.shape)\n",
    "src_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubR7ddc9D3D1"
   },
   "source": [
    "The BertAbs model we are finetuning is an encoder decoder model. To train it we will need to pass it a target sequence. Let's use this as our target summary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrfgtpycD3D1"
   },
   "outputs": [],
   "source": [
    "short_sum = [\"An introduction and greeting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsIedTTgD3D6"
   },
   "source": [
    "The encoding of the summary is slightly more complicated. Take this next section with a slight grain of salt, since although the following works, I'm not totally on top of everything that's going on. The situation is something like this. Although Bert is the model responsible for encoding text and making predictions about the relative likelihood of various words, the text generation itself is handled by an architecture from the Open Neural Machine Translation repository on Github. This handles things like beam search, which stops our model sounding like we've just repeatedly pressed the top item on our keyboard's predicted text.  \n",
    "\n",
    "This Translator doesn't know anything about Bert's [CLS] or [SEP] token conventions. It works by being given a [BOS] (beginning of sentence) tag. After this, it predicts new words until eventually it predicts an [EOS] (end of sentence) tag and comes to a stop. Let's see how this affects the way we encode our summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsczoUzXD3D7"
   },
   "source": [
    "We start by encoding the summary in the way we did before, but we will discard the [CLS] and [SEP] tags that bookend the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzFkc2EvD3D8",
    "outputId": "0701bf71-0469-4113-e7bd-113431e3c17f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2019, 4955, 1998, 14806]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflat_sum = [tokenizer.encode(s)[1:-1] for s in short_sum]\n",
    "unflat_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KorypG8GD3D_"
   },
   "source": [
    "We flatten it like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYLjt1oFD3EA",
    "outputId": "cba1da7b-d214-4588-9c16-f4781f6281bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2019, 4955, 1998, 14806]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_sum = [item for sublist in unflat_sum for item in sublist]\n",
    "flat_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4Mlto1PD3ED"
   },
   "source": [
    "Then we add the [BOS] and [EOS] tags. We will use the first two unused spaces in Bert's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feupD5VbD3EE",
    "outputId": "7c2b77b4-9ee7-4490-f266-e0009ab607df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2019, 4955, 1998, 14806, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols={\"BOS\": tokenizer.vocab[\"[unused0]\"], \"EOS\": tokenizer.vocab[\"[unused1]\"]}\n",
    "encoded_sum = [symbols['BOS']] + flat_sum + [symbols['EOS']]\n",
    "encoded_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVbACIIhD3EH"
   },
   "source": [
    "We will pad it like we did before. However, we will also add an extra piece of padding to bring the size of the encoded summary up to 513. I will explain why we do this at the end of this section. For now, just go with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGbth0MyD3EI",
    "outputId": "9e5cdd8c-c004-4052-f91c-86b9344773df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  2019,  4955,  1998, 14806,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sum = encoded_sum + [tokenizer.pad_token_id] * (512 - len(encoded_sum))\n",
    "padded_sum += [tokenizer.pad_token_id]\n",
    "tensor_sum = torch.tensor([padded_sum])\n",
    "print(tensor_sum.shape)\n",
    "tensor_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qm6wOkF4D3EK"
   },
   "source": [
    "The model will also require an attention mask like before. We don't have to provide segment embeddings this time, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MASzHEUFD3EK",
    "outputId": "2c7f6e43-883f-44ae-d98f-02a5ea285abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask = torch.zeros_like(tensor_sum)\n",
    "tgt_mask[tensor_sum != tokenizer.pad_token_id] = 1 \n",
    "print(tgt_mask.shape)\n",
    "tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRBaNUTBD3EO"
   },
   "source": [
    "That's a lot of preprocessing! Let's give it a bit of refactoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkrRpJxRD3EO"
   },
   "outputs": [],
   "source": [
    "def encode_text(text, tokenizer, symbols, is_summary=False):\n",
    "    if is_summary:\n",
    "        encoded = [tokenizer.encode(s)[1:-1] for s in text]\n",
    "    else:\n",
    "        encoded = [tokenizer.encode(s) for s in text]\n",
    "        \n",
    "    flattened = [item for sublist in encoded for item in sublist]\n",
    "    \n",
    "    if is_summary:\n",
    "        return [symbols['BOS']] + flattened + [symbols['EOS']] \n",
    "    \n",
    "    return flattened\n",
    "\n",
    "def create_seg_embs(encoded_text, tokenizer):\n",
    "    segment_embeddings = []\n",
    "    sentence_num = 0 \n",
    "    for item in encoded_text:\n",
    "        segment_embeddings.append(sentence_num % 2)\n",
    "        if item == tokenizer.sep_token_id:\n",
    "            sentence_num += 1\n",
    "            \n",
    "    return segment_embeddings\n",
    "\n",
    "def pad(encoded_text, seq_length, tokenizer, symbols, is_summary=False):\n",
    "    if len(encoded_text) > seq_length:\n",
    "        if is_summary:\n",
    "            encoded_text = encoded_text[:seq_length]\n",
    "        else:\n",
    "            sent_sep_idxs = [idx for idx, t in enumerate(encoded_text) if t == tokenizer.sep_token_id and idx < seq_length]\n",
    "            last_sent_sep_idx = min(max(sent_sep_idxs)+1 if (len(sent_sep_idxs) > 0) else seq_length, seq_length)\n",
    "            encoded_text = encoded_text[:last_sent_sep_idx]\n",
    "    \n",
    "    if len(encoded_text) < seq_length:\n",
    "        encoded_text.extend([tokenizer.pad_token_id] * (seq_length - len(encoded_text)))\n",
    "    \n",
    "    \n",
    "    if is_summary:\n",
    "        encoded_text += [tokenizer.pad_token_id]\n",
    "\n",
    "    return encoded_text\n",
    "\n",
    "def create_mask(text_tensor):\n",
    "    mask = torch.zeros_like(text_tensor)\n",
    "    mask[text_tensor != tokenizer.pad_token_id] = 1 \n",
    "    \n",
    "    return mask\n",
    "\n",
    "def collate_function(data, tokenizer, symbols, block_size, training):\n",
    "    encoded_stories = [encode_text(story, tokenizer, symbols) for _, story, summary in data]\n",
    "    encoded_summaries = [encode_text(summary, tokenizer, symbols, True) for _, story, summary in data]\n",
    "    story_segembs = [create_seg_embs(s, tokenizer) for s in encoded_stories]\n",
    "        \n",
    "    padded_stories = torch.tensor([pad(s, block_size, tokenizer, symbols) for s in encoded_stories]).long()\n",
    "    padded_summaries = torch.tensor([pad(s, block_size, tokenizer, symbols, True) for s in encoded_summaries]).long()\n",
    "    padded_segembs = torch.tensor([pad(s, block_size, tokenizer, symbols) for s in story_segembs]).long()\n",
    "    \n",
    "    stories_mask = create_mask(padded_stories)\n",
    "    summaries_mask = create_mask(padded_summaries)\n",
    "    \n",
    "    if training:\n",
    "        return [padded_stories, padded_summaries, padded_segembs, stories_mask, summaries_mask], padded_summaries[:,1:]\n",
    "    else:\n",
    "        Batch = namedtuple(\"Batch\", [\"document_names\", \"batch_size\", \"src\", \"segs\", \"mask_src\", \"tgt_str\"])\n",
    "        names = [name for name, _, _ in data]\n",
    "        summaries = [\" \".join(summary_list) for _, _, summary_list in data]\n",
    "        batch = Batch(\n",
    "            document_names=names,\n",
    "            batch_size=len(encoded_stories),\n",
    "            src=padded_stories.to(args.device),\n",
    "            segs=padded_segembs.to(args.device),\n",
    "            mask_src=stories_mask.to(args.device),\n",
    "            tgt_str=summaries,\n",
    "        )\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7yyPsbqD3EQ"
   },
   "source": [
    "You see how it all revolves around a single function, called _collate_function()_, because it's a function that collates (Has anyone ever heard that word anywhere else? Like, ever?). Anyway, this will be responsible for gathering up a batch of data, processing it in the way described above, and passing it on to the model.\n",
    "\n",
    "Notice that we return all the tensors in a list, and then return padded_summaries as a separate item with the first item in each sequence removed. I think this is because the NMT model which does the text generation will initialise itself with a [BOS] token, so we should not provide one. However, not providing one would leave that dimension with a shape of 511, not the 512 our model expects. Now you see why we appended an extra padding token earlier to make the summaries and summary masks sequence length 513. \n",
    "\n",
    "At the bottom of the function, we return our output as a list if we are passing this to the Bert model for training, or as a namedtuple if we are passing it to the NMT model for inference. More on that distinction at the end of the notebook. For now, just assume training is set to **True**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfSPE7kTD3ER"
   },
   "source": [
    "We can get the pretrained weights from HuggingFace like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "dc35566d29e2440db1980f3aa4c0ecdc"
     ]
    },
    "colab_type": "code",
    "id": "bcNoV-1TD3ER",
    "outputId": "b3332542-b7bd-4e00-c9f2-d977ef1c468b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f4a850295b48efacb78017d83cf8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=886341169.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertAbsConfig(max_pos=args.block_size)\n",
    "model = BertAbs.from_pretrained(\n",
    "    'remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization', \n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGMlnROJD3EU"
   },
   "source": [
    "Let's make a toy prediction on the first couple of items in our training set, to make sure everything is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pnIkXnbD3EU",
    "outputId": "3ea1e8cb-1d3d-4f53-8f6c-d632bfbf791e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 30522])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-24.8347, -14.6888,  -8.7769,  ..., -12.2642, -12.2642, -12.2643],\n",
       "         [-24.4808, -22.1490, -11.1257,  ..., -12.7708, -12.7706, -12.7713],\n",
       "         [-25.6597, -19.3884,  -9.7603,  ..., -12.6562, -12.6563, -12.6560],\n",
       "         ...,\n",
       "         [-25.0220, -19.3217,  -4.1826,  ..., -13.2789, -13.2787, -13.2795],\n",
       "         [-25.0087, -19.3320,  -4.2812,  ..., -13.2810, -13.2808, -13.2816],\n",
       "         [-25.0038, -19.3382,  -4.3466,  ..., -13.2805, -13.2803, -13.2811]],\n",
       "\n",
       "        [[-26.3382, -13.4584, -15.1853,  ..., -14.3906, -14.3907, -14.3906],\n",
       "         [-25.8751, -18.9378, -11.6863,  ..., -12.3040, -12.3042, -12.3035],\n",
       "         [-24.1931, -18.7458, -13.4333,  ..., -11.7813, -11.7814, -11.7811],\n",
       "         ...,\n",
       "         [-24.3471, -17.7585,  -3.4924,  ..., -12.8181, -12.8182, -12.8180],\n",
       "         [-24.3707, -17.8162,  -3.5839,  ..., -12.8285, -12.8286, -12.8284],\n",
       "         [-24.3866, -17.8917,  -3.6716,  ..., -12.8507, -12.8508, -12.8505]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[padded_stories, padded_summaries, padded_segembs, stories_mask, summaries_mask], labels = collate_function(\n",
    "    [train_ds[1], train_ds[2]], tokenizer, symbols, args.block_size, training=True\n",
    ")\n",
    "\n",
    "preds = model(padded_stories, padded_summaries, padded_segembs, stories_mask, summaries_mask)\n",
    "print(preds.shape)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bn9_RaeGD3EX"
   },
   "source": [
    "Looks good! Now let's talk about how we train this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivFoLaN7D3EY"
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBzoRBkkD3EZ"
   },
   "source": [
    "To train a model, we need a loss function. I'm going to throw my hands up a little bit here, because the [loss function in the authors' code](https://github.com/nlpyang/PreSumm/blob/master/src/models/loss.py) is more like a loss file. They've ported over a great deal of code from the OpenNMT repository we discussed earlier. No doubt it's very clever and efficient, but I honestly have no clue what most of it means. I thought sharding was what the Ethereum crowd did. I'd love to dive into it at some point, but for now I'm going to grab a loss function I can understand and fit into fewer lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX_pOlMbD3EZ"
   },
   "source": [
    "In the 3rd version of the Fastai course, Jeremy Howard [talks about the label smoothing cross entropy loss function](https://youtu.be/vnOpEwmtFJ8?t=1112). Click on the link. The discussion is only a couple of minutes long. I'm going to use that. We have to make one change, though, which is to add an ignore index parameter. This will tell the loss function to ignore the areas we masked out earlier. I've also added _reduce_loss()_ and _lin_comb()_ as class methods. They were defined earlier in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HGPeV_AD3Ea"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, eps:float, reduction, ignore_index):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = self.reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction, ignore_index=self.ignore_index)\n",
    "        return self.lin_comb(loss/c, nll, self.eps)\n",
    "    \n",
    "    def reduce_loss(self, loss, reduction='mean'):\n",
    "        return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "    \n",
    "    def lin_comb(self, v1, v2, beta): \n",
    "        return beta*v1 + (1-beta)*v2\n",
    "    \n",
    "def summaries_loss_fn(inputs, targs):\n",
    "    loss_fn = FlattenedLoss(\n",
    "        partial(\n",
    "            LabelSmoothingCrossEntropy, eps=0.1, reduction='mean', ignore_index=tokenizer.pad_token_id\n",
    "        )\n",
    "    )\n",
    "    loss = loss_fn(inputs, targs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vn8D2MjED3Ed",
    "outputId": "7b1dd807-2ab5-4f5a-c337-f4934824e705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8297, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = summaries_loss_fn(preds, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09vAsVFiD3Ef"
   },
   "source": [
    "Losses for seq2seq models are fairly uninterpretable. In the Fastai's NLP course, [Rachel Thomas uses the following function to calculate accuracy](https://youtu.be/IfsjMg4fLWQ?t=1633), which we will use as a metric. It's not particually interpretable, either, to be honest, but nice to have. We've already done our padding, so we can take those lines out of her implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3ZNjoxfD3Ef"
   },
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=-1):    \n",
    "    return (out.argmax(2)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YRSh-PND3Eh"
   },
   "source": [
    "The authors describe a training schedule they have developed in their paper. They train on an extractive summarisation task before moving on the abstractive. They also mention using two different Adam optimisers for the encoder and decoder layers of their model, with different warm-up periods for their learning rates. \n",
    "\n",
    "I'd love to try and re-implement their training schedule, but I'm on a budget. So I'm only going to finetune their weights on an abstractive task. Furthermore, looking at their description, I feel like a lot of their ideas are captured fairly well by the one cycle scheduling and layer freezing functionality in Fastai. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Hcti5WlD3Eh"
   },
   "source": [
    "We can turn our data into a Fastai databunch very easily. This is where the _collate_function()_ from earlier comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcca5Oz2D3Ei"
   },
   "outputs": [],
   "source": [
    "data = DataBunch.create(\n",
    "    train_ds, \n",
    "    valid_ds, \n",
    "    bs=args.batch_size, \n",
    "    collate_fn=partial(\n",
    "        collate_function, \n",
    "        tokenizer=tokenizer, \n",
    "        symbols=symbols, \n",
    "        block_size=args.block_size, \n",
    "        training=True\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XpA4ZE-D3Ej"
   },
   "source": [
    "Before I create a Fastai Learner object, I'll put all the model loading functionality into the cell below. There are three possible ways we could load our Bert weights. If _pretrained_ is **False**, we just load the raw Bert weights. Do this if you want to reproduce or improve on the paper's training schedule and results. If _pretrained_ is *True* but _path_ is **None** we will load the pretrained BertSum weights. If you want to load your own BertSum weights after your own finetuning, make _pretrained_ equal **True** and specify a _path_ to the weights file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FI4nqEEVD3Ek"
   },
   "outputs": [],
   "source": [
    "def load_model(pretrained=False, path=None): \n",
    "    config = BertAbsConfig(max_pos=args.block_size)\n",
    "    if pretrained:    \n",
    "        if path:\n",
    "            model = BertAbs.from_pretrained(\n",
    "                \"remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization\", \n",
    "                state_dict=torch.load(path, map_location=torch.device(args.device)), \n",
    "                config=config) \n",
    "        else: \n",
    "            model = BertAbs.from_pretrained(\n",
    "                \"remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization\", \n",
    "                config=config\n",
    "            )\n",
    "    else:\n",
    "        model = BertAbs(args=config)\n",
    "\n",
    "    return model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTnz_AQxD3El"
   },
   "outputs": [],
   "source": [
    "model = load_model(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiPU3gfJD3Ep"
   },
   "source": [
    "We'll use the beta values from the paper for Adam. We will also split the layer groups into the Bert encoder and transformer decoder like they do in the paper. We'll use a learning rate of 2e-3 like in the paper initially, but lower it when we unfreeze the whole model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObVE_f1zD3Eq"
   },
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    data, \n",
    "    model, \n",
    "    opt_func=partial(Adam, lr=2e-3, betas=(args.adam_b1, args.adam_b2)),\n",
    "    loss_func=summaries_loss_fn,\n",
    "    metrics=[seq2seq_acc],\n",
    "    callback_fns=ShowGraph\n",
    ")\n",
    "learn.path = Path('..')\n",
    "learn = learn.split([model.bert, model.decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WYIcfdlD3Es"
   },
   "source": [
    "We'll freeze the encoder layers since these are probably more well-trained than those in the decoder – and now we can hit train! For speed, I've limited the training to just an epoch over a subset of the data. You can specify the size of the subset in the args object. Set it to **None** if you want all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19rHdfXcD3Es",
    "outputId": "0780d06e-f276-4d4f-bbf9-ec9285c7367e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.201889</td>\n",
       "      <td>4.042458</td>\n",
       "      <td>0.084863</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 4.0424580574035645.\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-1)\n",
    "learn.fit_one_cycle(\n",
    "    1, \n",
    "    max_lr=2e-3,\n",
    "    moms=(0.8, 0.7),\n",
    "    wd=0.1,\n",
    "    callbacks=[\n",
    "        SaveModelCallback(learn, every='improvement', monitor='valid_loss', name=f\"{args.model_name}_dec\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unlqP-5UD3Eu"
   },
   "source": [
    "And now we will unfreeze all the layers, drop the learning rate and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IeXXUi7D3Eu",
    "outputId": "f6c588f8-8a44-48a2-af2a-608ac7e5868d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.674384</td>\n",
       "      <td>4.023995</td>\n",
       "      <td>0.085742</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 4.023995399475098.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(\n",
    "    1, \n",
    "    max_lr=slice(2e-5, 2e-4),\n",
    "    moms=(0.8, 0.7),\n",
    "    wd=0.1,\n",
    "    callbacks=[\n",
    "        SaveModelCallback(learn, every='improvement', monitor='valid_loss', name=f\"{args.model_name}_encdec\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLjszP0nD3Ex"
   },
   "outputs": [],
   "source": [
    "learn = learn.load(f\"{args.model_name}_encdec\")\n",
    "torch.save(learn.model.state_dict(), f\"../models/{args.model_name}_encdec_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJzzlpEZD3E0"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4SQN8DiD3E0"
   },
   "source": [
    "So now you want to evaluate how well your model is working. Let's create a function for summarising an article, or group of articles. I won't go into huge detail about how this works since it's a bit of a black box to me still. The _build_predictor()_ function comes from the _modelling_bertabs.py_ in the HuggingFace repo. It constructs a Translator object. It works. You can read through the code there. _format_summary()_ is also from the HuggingFace repo. I've added a few extra .replace()s to remove the white space before punctuation marks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_summary(translation):\n",
    "    raw_summary, _, _ = translation\n",
    "    summary = (raw_summary.replace(\"[unused0]\", \"\")\n",
    "                          .replace(\"[unused3]\", \"\")\n",
    "                          .replace(\"[PAD]\", \"\")\n",
    "                          .replace(\"[unused1]\", \"\")\n",
    "                          .replace(r\" +\", \" \")\n",
    "                          .replace(\" [unused2] \", \". \")\n",
    "                          .replace(\"[unused2]\", \"\")\n",
    "                          .replace(\" .\", \".\")\n",
    "                          .replace(\" ,\", \",\")\n",
    "                          .replace(\" ?\", \"?\")\n",
    "                          .replace(\" !\", \"!\")\n",
    "                          .strip())\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgTPxwgND3E1"
   },
   "outputs": [],
   "source": [
    "def summarise_articles(input_list, tokenizer, symbols, model):\n",
    "    iterator = DataLoader(\n",
    "        input_list, \n",
    "        sampler=SequentialSampler(input_list), \n",
    "        batch_size=min(len(input_list), args.batch_size), \n",
    "        collate_fn=partial(\n",
    "            collate_function, \n",
    "            tokenizer=tokenizer, \n",
    "            symbols=symbols, \n",
    "            block_size=args.block_size, \n",
    "            training=False\n",
    "        ),\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    summaries = []\n",
    "    predictor = build_predictor(args, tokenizer, symbols, model)\n",
    "    for batch in progress_bar(iterator):\n",
    "        batch_data = predictor.translate_batch(batch)\n",
    "        translations = predictor.from_batch(batch_data)\n",
    "        summaries.extend([format_summary(t) for t in translations])\n",
    "            \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab1S5R6tD3E4"
   },
   "source": [
    "You can pass the one of train_ds, valid_ds, or test_ds if you want to evaluate on the dataset. If you want to try out your model on some new articles, paste them into _.txt_ files in a folder. Set _args.stories_folder_ to be the path to that folder. Then use the cell below to make your predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ra0XLijD3E4",
    "outputId": "9fa499a9-dc3a-4d34-c008-142a4003f620"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(pretrained=True, path=f\"../models/{args.model_name}_encdec_weights.pth\")\n",
    "\n",
    "input_list = []\n",
    "for file in glob.glob(f\"{args.stories_folder}/*.txt\"):\n",
    "    text = open(file).read()\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.split('(?<=\\w[!\\?\\.])', text) \n",
    "    tup = ('', text, [''])\n",
    "    input_list.append(tup)\n",
    "\n",
    "summaries = summarise_articles(input_list, tokenizer, symbols, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nh-d0gDdD3E6",
    "outputId": "84f3c223-e727-4ead-a7c0-2f590d7bd42a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['university of british columbia researchers have found a cheap, sustainable way to build a solar cell using bacteria that convert light to energy. the research could be a step toward wider adoption of solar power in places like british columbia and parts of northern europe where overcast skies are common. a handful of islamic extremist groups have pledged allegiance to is.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmEdjOwCD3E8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "blog.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
